{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"google.colab\" in str(get_ipython()):\n",
    "    !pip install mlflow\n",
    "\n",
    "import mlflow\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "#Set up MLFlow via DAGSHub\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = '2Duffman'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'f6651f529b37bdd5aa99d6a092e7d48359374423'\n",
    "os.environ['MLFLOW_TRACKING_PROJECTNAME'] = 'Symbolic-Regression'\n",
    "mlflow.set_tracking_uri(f'https://dagshub.com/' + os.environ['MLFLOW_TRACKING_USERNAME']\n",
    "                        + '/' + os.environ['MLFLOW_TRACKING_PROJECTNAME'] + '.mlflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "if \"google.colab\" in str(get_ipython()):\n",
    "  data = pd.read_csv('drive/MyDrive/distance_8.csv')\n",
    "else:\n",
    "  data = pd.read_csv(\"distance_8.csv\")\n",
    "\n",
    "# Define the target column\n",
    "target = \"saldo_final_target\"\n",
    "\n",
    "# Function to check if time is present in the string\n",
    "def check_time(s):\n",
    "    first_colon = s.find(':')\n",
    "    if first_colon == -1:\n",
    "        return s + ' 00:00:00'\n",
    "    else:\n",
    "        return s\n",
    "\n",
    "# Apply the function to the 'delivery_start' column\n",
    "data['delivery_start'] = data['delivery_start'].apply(check_time)\n",
    "\n",
    "# Convert 'delivery_start' to datetime\n",
    "data['delivery_start'] = pd.to_datetime(data['delivery_start'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Create 'year' column\n",
    "data['year'] = data['delivery_start'].dt.year\n",
    "\n",
    "# Create 'day' column with day of the year\n",
    "data['day'] = data['delivery_start'].dt.dayofyear\n",
    "\n",
    "# Create 'time' column with minutes since midnight\n",
    "data['time'] = data['delivery_start'].dt.hour * 60 + data['delivery_start'].dt.minute\n",
    "\n",
    "# Create cyclic representations of 'day' and 'time'\n",
    "data['day_sin'] = np.sin(2 * np.pi * data['day'] / 365)\n",
    "data['day_cos'] = np.cos(2 * np.pi * data['day'] / 365)\n",
    "data['time_sin'] = np.sin(2 * np.pi * data['time'] / 1440)\n",
    "data['time_cos'] = np.cos(2 * np.pi * data['time'] / 1440)\n",
    "\n",
    "# Drop 'day' and 'time' columns\n",
    "data = data.drop(['day', 'time', 'delivery_start', 'floor_day_target'], axis=1)\n",
    "\n",
    "# Separate the features and the target variable\n",
    "X = data.drop(target, axis=1)\n",
    "Y = data[target]\n",
    "\n",
    "#Split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "scaler_target = StandardScaler()\n",
    "\n",
    "# Fit the scalers to the data and transform it\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "Y_train_scaled = scaler_target.fit_transform(Y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Transform the test data\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "Y_test_scaled = scaler_target.transform(Y_test.values.reshape(-1, 1))\n",
    "\n",
    "# Flatten the arrays\n",
    "Y_train_scaled = Y_train_scaled.flatten()\n",
    "Y_test_scaled = Y_test_scaled.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking 2 parameter combinations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\morit\\miniconda3\\envs\\symreg\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "c:\\Users\\morit\\miniconda3\\envs\\symreg\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "import time\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'C': [0.6,0.62,0.64,0.66,0.68,0.7,0.72,0.74,0.76,0.78,0.8],\n",
    "    'epsilon': [1.4,1.45,1.5,1.55,1.6,1.65,1.7,1.75,1.8,2,4],\n",
    "    'kernel': ['rbf'],\n",
    "    'tol': [0.9],\n",
    "    'max_iter': [2000]\n",
    "}\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = []\n",
    "\n",
    "# Create a ParameterGrid instance from the parameter grid\n",
    "param_grid_instance = ParameterGrid(param_grid)\n",
    "print('Checking {} parameter combinations.'.format(len(param_grid_instance)))\n",
    "\n",
    "# Loop over the parameters\n",
    "for params in param_grid_instance:\n",
    "    # Create and fit the model\n",
    "    start_time = time.time()\n",
    "    model = SVR(**params)\n",
    "    model.fit(X_train_scaled, Y_train_scaled)\n",
    "    end_time = time.time()\n",
    "    fitting_time = end_time - start_time\n",
    "    \n",
    "    # Make predictions\n",
    "    Y_pred_scaled = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Transform the predictions back to the original space\n",
    "    Y_pred = scaler_target.inverse_transform(Y_pred_scaled.reshape(-1, 1))\n",
    "\n",
    "    # Compute the score\n",
    "    score = mean_squared_error(Y_test, Y_pred, squared=False)\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        for key, value in params.items():\n",
    "            mlflow.log_param(key, value)\n",
    "        mlflow.log_param('scaled', True)\n",
    "        mlflow.log_metric('rmse', score)\n",
    "        mlflow.log_metric('fitting_time', fitting_time)\n",
    "    \n",
    "    # Append the results to the DataFrame\n",
    "    results.append({**params, 'score': score})\n",
    "    \n",
    "    # Convert the list to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    results_df.to_csv('grid_search_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "symreg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
